{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import utils\n",
    "import scipy.ndimage as ndimage\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters:\n",
    "    def __init__(self):\n",
    "        self.image_dir = \"../WFLW_images/\"\n",
    "        self.train_annotations = \"../WFLW_annotations/list_98pt_rect_attr_train_test/list_98pt_rect_attr_train.txt\"\n",
    "        self.test_annotations = \"../WFLW_annotations/list_98pt_rect_attr_train_test/list_98pt_rect_attr_test.txt\"\n",
    "        self.data_transform = transforms.Compose([Resize(224), Normalize(), ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class keypoint_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, annotation_file, transforms = None):\n",
    "        self.keypoints = pd.read_csv(annotation_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keypoints)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.keypoints.iloc[idx, 2016]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        image = Image.open(image_path).convert(\"L\")\n",
    "        keypoints = self.keypoints.iloc[idx, 0:196].as_matrix()\n",
    "        keypoints = keypoints.astype('float').reshape(-1, 2)\n",
    "        dataset = {'image':image, 'keypoints':keypoint}\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        image = image/255.0\n",
    "        \n",
    "        key_pts = (key_pts - 100)/50.0 # assume: mean = 100, std = 50\n",
    "        return {'image': image, 'keypoints': key_pts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "    # Arg: Desired output size \n",
    "    #   --> if tupple : returns output of the tuple size\n",
    "    #   --> if int : Smaller Edge = given int\n",
    "    #                Longer Edge = given int * (orig smaller edge / orig longer edge)\n",
    "    #                (keeps the original ratio the same)\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        h, w = image.shape[:2]\n",
    "        \n",
    "        if(isinstance(self.output_size, tuple)):\n",
    "            new_h, new_w = self.output_size\n",
    "        else:\n",
    "            if(h <= w):\n",
    "                new_h, new_w = self.output_size, self.output_size*(w/h)\n",
    "            else:\n",
    "                new_h, new_w = self.output_size*(h/w), self.output_size\n",
    "        \n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "        new_image = cv2.resize(image, (new_w, new_h))\n",
    "        #  \"*\" : [np.arr1 * np.arr2] :\n",
    "        #           (1) Both arrays have SAME dimension: ELEMENTWISE MULTIPLICAION \n",
    "        #           (2) Same # of columns & 1 array has 1 row :  \n",
    "        #               ELEMENTWISE MULTIPLICAION w/ that 1 row with every row of the longer arr\n",
    "        \n",
    "        new_key_pts = key_pts * [new_w/w, new_h/h]\n",
    "        \n",
    "        return { 'image' : new_image, 'keypoints' : new_key_pts }   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, key_pts = sample['image'], sample['keypoints']\n",
    "        \n",
    "        if(len(image.shape) == 2): # if image has NO 3rd grayscale channel (1)\n",
    "            image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "            \n",
    "        # Put grayscale channel at the 1st dimension, because:\n",
    "        # Numpy image: [H, W, C]  &  Tensor image: [C, H, W]\n",
    "        image = image.transpose((2, 0, 1)) # make (0, 1, 2) --> (2, 0, 1)\n",
    "        return {'image': torch.from_numpy(image), 'keypoints': torch.from_numpy(key_pts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = Parameters()\n",
    "train_dataset = keypoint_dataset(parameters.image_dir, parameters.train_annotations)\n",
    "test_dataset = keypoint_dataset(parameters.image_dir, parameters.test_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=128,num_workers=0,shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=128,num_workers=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
