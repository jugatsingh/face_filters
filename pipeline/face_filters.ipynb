{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keypoint_model import keypoint_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(data_dir, file_name):\n",
    "    path = os.path.join(data_dir, file_name)\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier(data_dir, file_name):\n",
    "    path = os.path.join(data_dir, file_name)\n",
    "    classifier = cv2.CascadeClassifier(path)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_bw(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image = cv2.equalizeHist(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(classifier, image):\n",
    "#     bw_image = convert_image_to_bw(image)\n",
    "    rects = classifier.detectMultiScale(image, 1.2, 2)\n",
    "#     for x, y, w, h in rects:\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    return rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_keypoints(model, image, faces, padding = 50):\n",
    "    image_copy = image.copy()\n",
    "    img_height, img_width = image.shape[0], image.shape[1]\n",
    "    images, keypoints = [], []\n",
    "    for coords in faces:\n",
    "        img = image[max(0, coords[1]-padding): min(coords[1]+coords[-1]+padding, img_height), \n",
    "                    max(0, coords[0]-padding): min(coords[0]+coords[2]+padding, img_width)]\n",
    "        img = (img/255.0).astype(np.float32)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        images.append(img)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "        else:\n",
    "            img = np.rollaxis(img, 2, 0)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = torch.from_numpy(img).type(torch.FloatTensor)\n",
    "        results = model.forward(img)\n",
    "        results = results.view(results.size()[0], 68, -1).cpu()\n",
    "        pred = results[0].cpu().data\n",
    "        pred = pred.numpy()\n",
    "        pred = pred * 50 + 100\n",
    "        keypoints.append(pred)\n",
    "    return images, keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keypoint_model()\n",
    "model.load_state_dict(torch.load(\"./models/keypoint_detection_model.pth\", map_location='cpu'))\n",
    "model.eval()\n",
    "classifier = get_classifier(data_dir=\"./models\", file_name=\"face_detection_model.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = get_image(data_dir=\"./images\", file_name=\"girl.jpg\")\n",
    "faces = detect_faces(classifier=classifier, image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, keypoints = detect_keypoints(faces=faces, image=image, model=model, padding=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_output(faces, test_outputs):  \n",
    "    for i, face in enumerate(faces):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(face)\n",
    "        plt.scatter(test_outputs[i][:, 0], test_outputs[i][:, 1], s=20, marker='.', c='m')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_sunglasses(image, sunglasses, key_pts):\n",
    "#     # Display sunglasses on top of the image in the appropriate place\n",
    "#     image_copy = np.copy(image)\n",
    "\n",
    "#     # top-left location for sunglasses to go\n",
    "#     # 17 = edge of left eyebrow\n",
    "#     x = int(key_pts[17, 0])\n",
    "#     y = int(key_pts[17, 1])\n",
    "\n",
    "#     # height and width of sunglasses\n",
    "#     # h = length of nose\n",
    "#     h = int(abs(key_pts[27,1] - key_pts[34,1]))\n",
    "#     # w = left to right eyebrow edges`\n",
    "#     w = int(abs(key_pts[17,0] - key_pts[26,0]))\n",
    "\n",
    "#     # read in sunglasses\n",
    "#     sunglasses = cv2.imread('filters/sunglasses.png', cv2.IMREAD_UNCHANGED)\n",
    "#     # resize sunglasses\n",
    "#     new_sunglasses =  cv2.resize(sunglasses, (w, h), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "#     # get region of interest on the face to change\n",
    "#     roi_color = image_copy[y:y+h,x:x+w]\n",
    "\n",
    "#     # find all non-transparent pts\n",
    "#     ind = np.argwhere(new_sunglasses[:,:,3] > 0)\n",
    "\n",
    "#     # for each non-transparent point, replace the original image pixel with that of the new_sunglasses\n",
    "#     for i in range(3):\n",
    "#         roi_color[ind[:,0],ind[:,1],i] = new_sunglasses[ind[:,0],ind[:,1],i]    \n",
    "#     # set the area of the image to the changed region with sunglasses\n",
    "#     image_copy[y:y+h,x:x+w] = roi_color\n",
    "#     plt.imshow(image_copy)\n",
    "#     return image_copy\n",
    "# #     plt.imshow(roi_color)\n",
    "#     # display the result!\n",
    "#     # plt.imshow(image_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dog_filter(face, filt):\n",
    "    filt_h, filt_w, _ = filt.shape\n",
    "    face_h, face_w, _ = face.shape\n",
    "    factor = min(face_h/filt_h, face_w/filt_w)\n",
    "    new_filt_h, new_filt_w = int(filt_h*factor), int(filt_w*factor)\n",
    "    new_filt_shape = (new_filt_w, new_filt_h)\n",
    "    resized_filter = cv2.resize(filt, new_filt_shape)\n",
    "    masked_face = face.copy()\n",
    "    non_white_pixels = (resized_filter < 250).all(axis = 2)\n",
    "    offset_h, offset_w = int((face_h-new_filt_h)/2), int((face_w-new_filt_w)/2)\n",
    "    masked_face[offset_h:offset_h+new_filt_h, offset_w:offset_w+new_filt_w][non_white_pixels] = resized_filter[non_white_pixels]\n",
    "    return masked_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog_face_filter(image, classifier, dog_filter):\n",
    "    image_h, image_w = image.shape[0], image.shape[1]\n",
    "    rectangles = detect_faces(classifier=classifier, image=image)\n",
    "    for x, y, w, h in rectangles:\n",
    "        y0, y1 = int(y - 0.25*h), int(y + 0.75*h)\n",
    "        x0, x1 = x, x + w\n",
    "        if x0 < 0 or y0 < 0 or x1 > image_w or y1 > image_h:\n",
    "            continue\n",
    "        image[y0: y1, x0: x1] = apply_dog_filter(image[y0: y1, x0: x1], dog_filter)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_filter_on_image(img, filt, off_x, off_y):\n",
    "    (h,w) = (filt.shape[0], filt.shape[1])\n",
    "    (imgH,imgW) = (img.shape[0], img.shape[1])\n",
    "    if off_y+h >= imgH: \n",
    "        filt = filt[0:imgH-off_y,:,:]\n",
    "    if off_x+w >= imgW:\n",
    "        filt = filt[:,0:imgW-off_x,:]\n",
    "    if off_x < 0:\n",
    "        filt = filt[:,abs(off_x)::,:]\n",
    "        w = filt.shape[1]\n",
    "        off_x = 0\n",
    "    for c in range(3):\n",
    "        img[off_y:int(off_y+h), off_x:int(off_x+w), c] =  \\\n",
    "        filt[:,:,c] * (filt[:,:,3]/255.0) +  img[off_y:off_y+h, off_x:off_x+w, c] * (1.0 - filt[:,:,3]/255.0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_filter(img, model,scale = 1.1, neighbors = 5, width = 30):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    features = model.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=scale,\n",
    "        minNeighbors=neighbors,\n",
    "        minSize=(width, width),\n",
    "        flags=cv2.CASCADE_SCALE_IMAGE\n",
    "    )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sunglasses_filter(img, filt, part_filter, off_x, off_y, off_y_image, actual_width, x, y, w, h):\n",
    "    (filt_h,filt_w) = (filt.shape[0], filt.shape[1])\n",
    "    xpos = x + off_x\n",
    "    ypos = y + off_y\n",
    "    factor = 1.0 * actual_width/filt_w\n",
    "    sub_img = img[y+off_y_image:y+h, x:x+w,:]\n",
    "    feature = get_part_filter(sub_img, part_filter, 1.3 , 10, 10)\n",
    "    if len(feature) != 0:\n",
    "        xpos, ypos = x, y + feature[0,1]\n",
    "    filt = cv2.resize(filt, (0,0), fx=factor, fy=factor)\n",
    "    img = overlay_filter_on_image(img, filt, xpos, int(ypos))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mustache_filter(img, filt, part_filter, off_x, off_y, off_y_image, actual_width, x, y, w, h):\n",
    "    (filt_h,filt_w) = (filt.shape[0], filt.shape[1])\n",
    "    xpos = x + off_x\n",
    "    ypos = y + off_y\n",
    "    factor = 1.0 * actual_width/filt_w\n",
    "    sub_img = img[y+off_y_image:y+h, x:x+w,:]\n",
    "    feature = get_part_filter(sub_img, part_filter, 1.3 , 10, 10)\n",
    "    if len(feature) != 0:\n",
    "        xpos, ypos = x, y + feature[0,1]\n",
    "        size_mustache = 1.2\n",
    "        factor = 1.0*(feature[0,2]*size_mustache)/filt_w\n",
    "        xpos =  x + feature[0,0] - int(feature[0,2]*(size_mustache-1)/2)\n",
    "        ypos = y + off_y_image + feature[0,1] - int(filt_h*factor)\n",
    "    filt = cv2.resize(filt, (0,0), fx=factor, fy=factor)\n",
    "    img = overlay_filter_on_image(img, filt, xpos, int(ypos))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, w, h = faces[0]\n",
    "haar_eyes = cv2.CascadeClassifier('./models/haarcascade_eye.xml')\n",
    "haar_mouth = cv2.CascadeClassifier('./models/Mouth.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglasses = cv2.imread(\"./filters/sunglasses.png\", -1)\n",
    "f = apply_sunglasses_filter(image.copy(), sunglasses, haar_eyes, 0, h/3, 0, w, x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "mustache = cv2.imread(\"./filters/mustache.png\", -1)\n",
    "g = apply_mustache_filter(image.copy(), mustache, haar_mouth, int(w/4), int(4*h/5), int(h/2), int(w/2), x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
